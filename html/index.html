<html>
<head>
   <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <meta name="Author" content="ECE User">
   <meta name="Source" content="http://davis.wpi.edu/~matt/courses/morph/2d.htm">
   <title>2d</title>
</head>

<body vlink="#551A8B" text="#000000" bgcolor="#FFFFFF" alink="#FF0000" link="#0000EE">
<h2>2D Image Morphing Algorithms</h2>
<h3>1. 2 Published Algorithms for Warping</h3>
<ul>
    <li><a href="#Mesh">Mesh warping</a></li>
    <li><a href="#3.%20Feature-Based%20Image">Feature-Based (Field) morphing</a></li>
</ul>

<h3>2.<a name="Mesh"></a>Mesh Warping[1]</h3>
<p>The mesh-warping algorithm relates features with nonuniform mesh in the
source and destination images, i.e., the images are broken up into
small regions that are mapped onto each other for the morph.</p>
<blockquote><img src="img/img017.jpg" height="256" width="437"></blockquote>
<p>The algorithm accepts a source image, a destination image and two
2D arrays of coordinates. The first array, S, specifies the coordinates
of control points in the source image. The second array, D, specifies their
corresponding positions in the destination image. Both S and D must have
the same dimensions in order to establish a one-to-one correspondence.</p>
<center><table cols="2" width="100%"><tbody>
<tr>
<td>
    <blockquote><img src="img/girl.jpg" height="170" width="205"></blockquote>
    <p>Source Image</p>
</td>
<td>
    <img src="img/tiger.jpg" height="166" width="203">
    <p>Destination Imge</p>
</td>
</tr>
</tbody></table></center>
<p>Figure2 Original Images for morphing</p>
<table cols="2" width="100%"><tbody>
<tr>
<td><blockquote><img src="img/gnode.jpg" height="122" width="149"></blockquote></td>
<td><img src="img/tnode.jpg" height="121" width="148"></td>
</tr></tbody></table>
<p>Figure3 Images with Control Points</p>
<p>Then two imges are processed through 2-pass warping with 2 output intermediate
images I1 and I2. The first pass is responsible for resampling each row
independently. It maps all initial image points coordinates (u, v) to their
(x, v) coordinates in the intermediate image , thereby positioning each
input point into its proper output column.The second pass then resamples
each column in intermediate image, mapping every (x, v) point to its final
(x, y) position in I1/I2. The 2D arrays in which the control points are
stored to impose a topology to the mesh.</p>
<p>More detail is that each frame in the transformation uses an interpolated
mesh M as the set of target positions for the input mesh points. M is computed
by performing linear interpolation between respective points in S and D.
The "warp" program actually plays an important role here since both I1
and I2 are each warped using M as the target mesh. Thus, I1 is warped using
meshes S and M. In addition, I2 is warped using meshes D and M. Now that
the landmarks of the source and target images are aligned, they are cross-dissolved
to generate a morph frame. Catmull-Rom cubic spline is used to implement
bicubic interpolation in [3] because it offers local control, although
any spline wourld suffice.</p>
<p>Result:</p>
<blockquote><img src="img/myavi.gif" height="122" width="149"></blockquote>
<p>Source code for Mesh-morphing: (Some changes are made to the image morphing
source codes written by George Wolberg in order to morphing the color images).</p>
<ol>
    <li>Transform a RGB format file to three BW format files in term of different color channel <a href="http://davis.wpi.edu/%7Ematt/courses/morph/seperate.htm">[code]</a></li>
    <li>Morphing Source Code (written by George Wolberg,1993.) [see detail at <a href="http://www.engr.ccny.cuny.edu/CSCWWW/faculty/wolberg/abstracts.html#cga97">http://www.engr.ccny.cuny.edu/CSCWWW/faculty/wolberg/abstracts.html#cga97</a>]
    <blockquote>
        <a href="http://davis.wpi.edu/%7Ematt/courses/morph/makefile.htm">Makefile</a>: dependency rules for creating "warp" and "morph"
        <br><a href="http://davis.wpi.edu/%7Ematt/courses/morph/msh.htm">meshwarp.h</a>: header file
        <br><a href="http://davis.wpi.edu/%7Ematt/courses/morph/warp.htm">warp.c</a>: main function for "warp"
        <br><a href="http://davis.wpi.edu/%7Ematt/courses/morph/morph.htm">morph.c</a>: main function for "morph"
        <br><a href="http://davis.wpi.edu/%7Ematt/courses/morph/meshwarp.htm">meshwarp.c</a>: workhorse mesh warping code
        <br><a href="http://davis.wpi.edu/%7Ematt/courses/morph/util.htm">util.c</a>: image I/O and memory allocation functions
        <br><a href="http://davis.wpi.edu/%7Ematt/courses/morph/cat.htm">catmullrom.c</a>: Catmull-Rom cubic spline interpolation.
    </blockquote>
    </li>
    <li>Merging three channel's BW format images into one RGB color image<a href="http://davis.wpi.edu/%7Ematt/courses/morph/merge.htm">[code]</a></li>
</ol>

<p>Pros and Cons:
<br>
<table cols="2" border="" width="100%"><tbody><tr>
<td><center>Pro</center></td><td><center>Con</center></td>
</tr>
<tr>
<td>
<ul>
    <li>Fast and intuitive</li>
    <li>Efficient algorithms exist for computing the mapping of each pixel from the control grid</li>
</ul>
</td>
<td>
<ul>
    <li>Trying to position dozens of mesh points around is like trying to push a rope; something is always forced where you don’t want it to go.</li>
    <li>The animator must specify in advance how many control points to use to control the image, then take those given points and move them to the correct locations.</li>
    <li>Points left unmodified or points for which the animator could not find an associating feature are still used by the warping algorithm.</li>
</ul>
</td>
</tr></tbody></table>
</p>

<h3><a name="3. Feature-Based Image"></a>3. Feature-Based Image Morphing [2]</h3>
<p>The field morphing algorithm uses lines to relate features in the source
image to features in the destination image. It is based upon fields of
influence surrounding two-dimensional control primitives. It applies the
reverse mapping as its ways of warping.</p>

<p><font size="-1">[ Note: There are 2 ways to warp an image. The first,
called forward mapping, scans through the source image pixel by pixel,
and copies them to teh apprpriate place in the destination image. The second,
reverse mapping, goes through the destination image pixel by pixel, and
samples the correct pixel from the source image. The most important feature
of inverse mapping is that every pixel in the destination image gets set
to something appropriate. In the forward mapping case, some pixels in the
destination might not get painted, and would have to be interpolated.]</font></p>
<h4>Transformation between one pair of lines</h4>
<p>A pair of lines (one defined relative to the source image, the other defined
relative to the destination image) defines a mapping from one image to
the other.</p>
<table cols="2" width="100%"><tbody><tr>
<td><img src="img/img019.jpg" height="78" width="229"><br>where u is the position along the line, and v is the distance from the line</td>
<td><img src="img/image2.jpg" height="144" width="300"></td>
</tr></tbody></table>
<p>The algorithms transforms each pixel coordinate by a rotation, translation,
and/or a scale, thereby transforming the whole image.</p>

<h4>Transformation between multiple pairs of lines</h4>
<p>Normally there are many features in images where transformation between
multiple pairs of lines are applied. It specifies more complex transformations.
A weighting of the coordinate transformations for each line is performed.
The weight is determined by the distance from X to the line.</p>
<center><img src="img/image4.jpg" border="0" height="160" width="300"></center>

<table cols="2" width="100%"><tbody><tr>
<td><img src="img/image3.gif" height="65" width="180"></td>
<td>where length is the length of a line, dist is the distance from the pixel to the line, and a, b, and p are constants that can be used to change the relative effect of the lines</td>
</tr></tbody></table>
<p>The multiple line algorithm is as follows:</p>
<blockquote>For each pixel X in the destination
<br> DSUM=0
<br> weightsum = 0
<br> For each line PiQi
<br> calculate u, v based on PiQi
<br> calculate X i based on u, v and P iQ i
<br> calculate displacement Di=X i-Xi for this line
<br> dist= shortest distance from X to PiQi
<br> weight = (lengthP / (a + dist))b
<br> DSUM += Di * weight
<br> weightsum += weigth
<br> X = X + DSUM / weightsum
<br> destinationImage(X) = sourceImage(X)</blockquote>

<h4>Process of Morphing between Two images</h4>

<ul>
    <li>Define corresponding lines in source image I0 and destination image I1.</li>
    <li>Each intermediate frame I of the metamorphosis is defined by creating a new set of line segments by interpolating the lines from their positions in I0 to the positions in I1.</li>
    <li>Both images I0 and I1 are distorted toward the position of the lines in I. These two resulting images are cross-dissolved throughout the metamorphosis.</li>
</ul>

<h4>Example</h4>
<table cols="2" width="100%">
<tbody><tr>
<td><img src="img/boy.jpg" height="106" width="150"><br> Source Image</td>
<td><img src="img/gg.jpg" height="105" width="150"><br> Destination Image</td>
</tr></tbody></table>
<br>
<table cols="2" width="100%"><tbody><tr>
<td><img src="img/image1.jpg" height="146" width="400"></td>
<td>Left figure is the first face distorted to the intermediate position without the grid or lines.</td>
</tr>
<tr>
<td><img src="img/image12.jpg" height="146" width="400"></td>
<td>Same as above figures with lines drawn over the faces.</td>
</tr>
<tr>
<td><img src="img/image3.jpg" height="142" width="400"></td>
<td>Left figure is the second face distorted to the intermediate position without the grid or lines.</td>
</tr>
<tr>
<td><img src="img/image44.jpg" height="143" width="400"></td>
<td>Same as above figures with lines drawn over the faces.</td>
</tr>
<tr>
<td><img src="img/image5.jpg" height="150" width="400"></td>
<td>Left figure shows the morphed image (right figure) with the interpolated lines drawn over it.</td>
</tr>
</tbody></table>

<h4>Advantage and disadvantage</h4>
<table cols="2" border="" width="100%"><tbody><tr>
<td><center>Advantages</center></td>
<td><center>Disadvantages</center></td>
</tr>
<tr>
<td>The only positions that are used in the algorithm are ones the animator explicitly created. Everything that is specified is moved exactly as the animator wants them moved, and everything else is blended smoothly based on those positions.</td>
<td>
<ul>
    <li>Speed problems: All line segments need to be referenced for every pixel. The runtime is proportional to the number of lines times the number of pixels in the image.</li>
    <li>Control: Between the lines, sometimes unexpected interpolations are generated.</li>
</ul>
</td>
</tr></tbody></table>

</body>
</html>
